# ğŸ¨ Pix2Pix Image Translation with Gradio

A user-friendly web interface for Pix2Pix image-to-image translation powered by Gradio. Transform your images using conditional GANs with an intuitive drag-and-drop interface!

![Pix2Pix Demo](https://img.shields.io/badge/Demo-Live-brightgreen) ![Python](https://img.shields.io/badge/Python-3.7+-blue) ![PyTorch](https://img.shields.io/badge/PyTorch-1.8+-red) ![Gradio](https://img.shields.io/badge/Gradio-Latest-orange)


<div align="center">
  <img src="pix2pix.gif" alt="Pix2Pix Demo" width="600"/>
  <p><em>Watch the magic happen! âœ¨</em></p>
</div>
"""

## ğŸŒŸ Features

- **ğŸ–¼ï¸ Interactive Web Interface** - Drag & drop image uploads with real-time preview
- **ğŸ”„ Multiple Model Support** - Switch between different transformation types
- **ğŸ“ Custom Model Upload** - Use your own trained Pix2Pix models (.pth/.pt files)
- **âš™ï¸ Configurable Parameters** - Adjust image size and processing options
- **ğŸ“± Mobile Friendly** - Responsive design that works on all devices
- **ğŸ“š Educational Content** - Built-in guides about Pix2Pix architecture and training
- **ğŸš€ One-Click Sharing** - Share your app instantly with Gradio's sharing feature

## ğŸ¯ Supported Transformations

| Type | Input | Output | Use Case |
|------|-------|--------|----------|
| ğŸ¨ **Sketch to Photo** | Hand-drawn sketches | Photorealistic images | Art creation, concept visualization |
| ğŸŒ† **Day to Night** | Daytime scenes | Nighttime scenes | Architectural visualization |
| ğŸ›°ï¸ **Satellite to Map** | Satellite imagery | Map-style images | Cartography, urban planning |
| ğŸ¨ **Custom Model** | Your training data | Your target domain | Any custom transformation |

## ğŸš€ Quick Start

### Prerequisites

- Python 3.7+
- CUDA (optional, for GPU acceleration)

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/pix2pix-gradio.git
   cd pix2pix-gradio
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the application:**
   ```bash
   python pix2pix_gradio.py
   ```

4. **Open your browser** and navigate to the displayed URL (usually `http://localhost:7860`)

## ğŸ“¦ Requirements

Create a `requirements.txt` file with:
```
gradio>=4.0.0
torch>=1.8.0
torchvision>=0.9.0
pillow>=8.0.0
numpy>=1.19.0
```

## ğŸ—ï¸ Project Structure

```
pix2pix-gradio/
â”œâ”€â”€ app.py      # Main application file
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ models/                # Directory for trained models (optional)
â”‚   â”œâ”€â”€ sketch2photo.pth
â”‚   â”œâ”€â”€ day2night.pth
â”‚   â””â”€â”€ satellite2map.pth
â”œâ”€â”€ examples/              # Sample images for testing
â”‚   â”œâ”€â”€ sketches/
â”‚   â”œâ”€â”€ daytime/
â”‚   â””â”€â”€ satellite/
â””â”€â”€ assets/               # Screenshots and documentation images
    â””â”€â”€ demo_screenshot.png
```

## ğŸ® How to Use

### Basic Usage

1. **Upload an image** by dragging and dropping or clicking the upload area
2. **Select transformation type** from the dropdown menu
3. **Adjust image size** if needed (128-512 pixels)
4. **Click "Transform Image"** and wait for the magic! âœ¨

### Using Custom Models

1. **Select "Custom Model"** from the transformation type dropdown
2. **Upload your trained model** (.pth or .pt file)
3. **Upload your input image**
4. **Click "Transform Image"** to see your custom transformation

### Example Workflow

```python
# For developers: Loading a custom model programmatically
generator = UNetGenerator(chnls_in=3, chnls_op=3)
generator.load_state_dict(torch.load('your_model.pth', map_location='cpu'))
generator.eval()
```

## ğŸ‹ï¸ Training Your Own Model

### Data Preparation

Organize your training data in paired format:
```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ A/  # Input images (e.g., sketches)
â”‚   â””â”€â”€ B/  # Target images (e.g., photos)
â””â”€â”€ test/
    â”œâ”€â”€ A/
    â””â”€â”€ B/
```

### Training Script Example

```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

# Initialize models
generator = UNetGenerator(chnls_in=3, chnls_op=3)
discriminator = Pix2PixDiscriminator(chnls_in=3)

# Loss functions
criterion_GAN = nn.MSELoss()
criterion_L1 = nn.L1Loss()
lambda_L1 = 100

# Training loop
for epoch in range(num_epochs):
    for real_A, real_B in dataloader:
        # Train Generator
        fake_B = generator(real_A)
        
        # Generator loss
        pred_fake = discriminator(real_A, fake_B)
        loss_GAN = criterion_GAN(pred_fake, torch.ones_like(pred_fake))
        loss_L1 = criterion_L1(fake_B, real_B)
        loss_G = loss_GAN + lambda_L1 * loss_L1
        
        # Backprop and optimize
        optimizer_G.zero_grad()
        loss_G.backward()
        optimizer_G.step()
        
        # Train Discriminator
        # ... discriminator training code
        
# Save the trained model
torch.save(generator.state_dict(), 'my_pix2pix_model.pth')
```

### Training Tips

- **Data Quality**: Use high-quality, well-aligned image pairs
- **Batch Size**: Start with batch size 1-4 depending on GPU memory
- **Learning Rate**: Use 0.0002 for both generator and discriminator
- **Epochs**: Train for 100-200 epochs typically
- **Monitoring**: Watch both generator and discriminator losses

## ğŸ”§ Architecture Details

### U-Net Generator
- **Encoder**: 8 downsampling layers with increasing channel dimensions
- **Decoder**: 7 upsampling layers with skip connections
- **Skip Connections**: Preserve fine details from encoder to decoder
- **Output**: Tanh activation for [-1, 1] range

### PatchGAN Discriminator
- **Architecture**: 4 convolutional layers
- **Patch Size**: 70x70 patches for local realism
- **Output**: Single value per patch (real/fake)

## ğŸ¨ Customization

### Adding New Model Types

1. **Add to dropdown options** in `model_type` variable
2. **Create model loading logic** in `load_model()` function
3. **Add documentation** in the info tabs

### Styling Customization

Modify the CSS in the `create_demo()` function:
```python
css = """
.gradio-container {
    font-family: 'Your-Font', sans-serif;
}
.gr-button-primary {
    background: your-gradient !important;
}
"""
```

## ğŸ› Troubleshooting

### Common Issues

**1. Model Loading Errors**
```
âŒ Error loading model: [Error message]
```
- Ensure your model file is compatible with the architecture
- Check that the model was saved correctly during training

**2. CUDA Out of Memory**
```
RuntimeError: CUDA out of memory
```
- Reduce the image size using the slider
- Use CPU-only mode by adding `map_location='cpu'` when loading models

**3. Image Processing Errors**
```
âŒ Error processing image: [Error message]
```
- Ensure your input image is in a supported format (PNG, JPG, JPEG)
- Check that the image isn't corrupted

### Performance Optimization

- **GPU Acceleration**: Ensure CUDA is properly installed for faster inference
- **Image Size**: Use smaller image sizes (128-256px) for faster processing
- **Model Optimization**: Use `torch.jit.script()` for production deployment

## ğŸ“Š Example Results

| Input Type | Processing Time | Quality Score |
|------------|----------------|---------------|
| 256x256 sketch | ~2-3 seconds | â­â­â­â­â­ |
| 512x512 photo | ~5-8 seconds | â­â­â­â­â­ |
| 1024x1024 image | ~15-20 seconds | â­â­â­â­ |

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit your changes**: `git commit -m 'Add amazing feature'`
4. **Push to the branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Contribution Ideas

- ğŸ¨ Add new pre-trained models
- ğŸ”§ Improve the user interface
- ğŸ“š Add more educational content
- ğŸ› Fix bugs and improve performance
- ğŸ“– Improve documentation

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Pix2Pix Paper**: [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004)
- **Gradio Team**: For the amazing web interface framework
- **PyTorch Team**: For the deep learning framework
- **Community**: Thanks to all contributors and users!


## ğŸŒŸ Star History

If you find this project helpful, please consider giving it a star! â­

[![Star History Chart](https://api.star-history.com/svg?repos=yourusername/pix2pix-gradio&type=Date)](https://star-history.com/#yourusername/pix2pix-gradio&Date)

---

<div align="center">

**Made with â¤ï¸ by [Your Name](https://github.com/yourusername)**

[ğŸŒŸ Star this repo](https://github.com/yourusername/pix2pix-gradio) â€¢ [ğŸ› Report Bug](https://github.com/yourusername/pix2pix-gradio/issues) â€¢ [ğŸ’¡ Request Feature](https://github.com/yourusername/pix2pix-gradio/issues)

</div>
